{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Gowalla.txt', 'r') as f:\n",
    "    data = f.readlines()\n",
    "    \n",
    "nodes = set() # users\n",
    "edges = [] # user links\n",
    "similarities = [] \n",
    "\n",
    "for entry in data:\n",
    "    node_1, node_2 = entry.split()\n",
    "    \n",
    "    nodes.add((int(node_1)))\n",
    "    edges.append((int(node_1), int(node_2)))\n",
    "\n",
    "    similarities.append(1) # 1 for similarity\n",
    "\n",
    "data = None\n",
    "    \n",
    "for node in nodes:\n",
    "    edges.append((node, node)) #self \n",
    "\n",
    "similarities = np.array(similarities, dtype=np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900654\n"
     ]
    }
   ],
   "source": [
    "NODES_NUM = 196591\n",
    "EDGES_NUM = 950327\n",
    "\n",
    "SELF_SIMILARITY_PARAMETER = -2 # custom self-similarity parameter, can be changed\n",
    "TRANSITIVITY = 5\n",
    "ITERATIONS = 10\n",
    "\n",
    "TOP_NUMBER = 10 # required to form top-10\n",
    "\n",
    "\n",
    "SIMILARITIES_NUM = len(similarities)\n",
    "print(SIMILARITIES_NUM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_responsibility(S, A, edges):\n",
    "    \n",
    "    V = S + A \n",
    "    R = S.copy()\n",
    "    \n",
    "    # two max is required to avoid self value being max value\n",
    "    max_sum_1 = np.repeat(-np.inf, NODES_NUM)\n",
    "    max_sum_2 = np.repeat(-np.inf, NODES_NUM)\n",
    "    \n",
    "    # to store node 2 for which node 1 has max V\n",
    "    paired_max = np.repeat(np.inf, NODES_NUM) \n",
    "\n",
    "\n",
    "    for i, (node_1, node_2) in enumerate(edges):\n",
    "        # two max V for each node\n",
    "        if max_sum_1[node_1] < V[i]:\n",
    "            max_sum_2[node_1] = max_sum_1[node_1]\n",
    "            max_sum_1[node_1] = V[i]\n",
    "\n",
    "            paired_max[node_1] = node_2\n",
    "\n",
    "        elif max_sum_2[node_1] < V[i]:\n",
    "            max_sum_2[node_1] = V[i]\n",
    "            \n",
    "    # update R\n",
    "    for i, (node_1, node_2) in enumerate(edges):\n",
    "        if paired_max[node_1] == node_2:\n",
    "            R[i] = R[i] - max_sum_2[node_1]\n",
    "        else:\n",
    "            R[i] = R[i] - max_sum_1[node_1]\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_availability(R, A, edges):\n",
    "    \n",
    "    R_copy = R.copy()\n",
    "    A_copy = A.copy()\n",
    "   \n",
    "    # max (0, R-value)\n",
    "    # if max (0, R-value) < 0 => max (0, R-value) = 0 (if negative make it zero)\n",
    "    \n",
    "    i = 0\n",
    "    while i < EDGES_NUM * 2:\n",
    "        if R_copy[i] < 0:\n",
    "            R_copy[i] = 0\n",
    "        i += 1\n",
    "            \n",
    "    R_sum = np.repeat(0, NODES_NUM) #np.full(0,n)\n",
    "    \n",
    "    for i, (node_1, node_2) in enumerate(edges):\n",
    "        R_sum[node_2] += R_copy[i]\n",
    "    \n",
    "    # update A\n",
    "    for i, (node_1, node_2) in enumerate(edges):\n",
    "        A[i] = R_sum[node_2] - R_copy[i]\n",
    "        \n",
    "    # find min\n",
    "    i = 0\n",
    "    while i < EDGES_NUM * 2:\n",
    "        A[i] = np.min([0, A[i]])\n",
    "        i += 1\n",
    "    \n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaders(A, R, edges, transitivity):\n",
    "    \n",
    "    AR_sum = A + R\n",
    "    \n",
    "    leaders = dict()\n",
    "    max_tmp = np.repeat(-np.inf, NODES_NUM)\n",
    "    \n",
    "\n",
    "    # for every node 1 find node 2 with max AR_sum\n",
    "    for i, (node_1, node_2) in enumerate(edges):\n",
    "        if AR_sum[i] > max_tmp[node_1]:   # update max if AR_sum[i] > saved value\n",
    "            max_tmp[node_1] = AR_sum[i]\n",
    "            leaders[node_1] = node_2\n",
    "    \n",
    "    for i in range(transitivity):        \n",
    "        for node in leaders.keys(): \n",
    "            leader_value = leaders[node]\n",
    "            if leaders[leader_value] != leader_value: # self\n",
    "                new_leader = leaders[leader_value]\n",
    "                leaders[node] = new_leader # update leader for node\n",
    "                \n",
    "    return leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinity_propagation(s, edges, self_similarity, iterations):\n",
    "\n",
    "    S = np.append(s, np.repeat(self_similarity, NODES_NUM)) # similarity + self-similarity\n",
    "    \n",
    "    R = np.repeat(0, S.shape[0])\n",
    "    A = np.repeat(0, S.shape[0])\n",
    "\n",
    "    for i in range(iterations):\n",
    "        R = get_responsibility(S, A, edges)\n",
    "        A = get_availability(R, A, edges)\n",
    "        print(\"Iteration №\", i + 1, \"in progress...\")\n",
    "        \n",
    "    result = get_leaders(R, A, edges, TRANSITIVITY)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration № 0 in progress...\n",
      "Iteration № 1 in progress...\n",
      "Iteration № 2 in progress...\n",
      "Iteration № 3 in progress...\n",
      "Iteration № 4 in progress...\n",
      "Iteration № 5 in progress...\n",
      "Iteration № 6 in progress...\n",
      "Iteration № 7 in progress...\n",
      "Iteration № 8 in progress...\n",
      "Iteration № 9 in progress...\n"
     ]
    }
   ],
   "source": [
    "clusters_leaders = affinity_propagation(similarities, edges, SELF_SIMILARITY_PARAMETER, ITERATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of clusters: 24801\n"
     ]
    }
   ],
   "source": [
    "clusters = sorted(list(set(clusters_leaders.values())))\n",
    "\n",
    "print(\"Total number of clusters:\", len(clusters)) # unique values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- PART 2 ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196591\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  cluster_id\n",
       "0        0           0\n",
       "1        1           1\n",
       "2        2           2\n",
       "3        3           3\n",
       "4        4           4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_df=(list(clusters_leaders.values()))\n",
    "\n",
    "print(len(clusters_df))\n",
    "df_clusters = pd.DataFrame(clusters_df)\n",
    "df_clusters = df_clusters.reset_index()\n",
    "df_clusters.columns = [\"user_id\", \"cluster_id\"]\n",
    "df_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of users with checkins:  107092\n"
     ]
    }
   ],
   "source": [
    "data = None\n",
    "\n",
    "with open('Gowalla_totalCheckins.txt', 'r') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "checkins = []\n",
    "for string in data:\n",
    "    location = int(string.split()[-1])\n",
    "    user = int(string.split()[0])\n",
    "    checkins.append((user, location)) # collect checkins per user\n",
    "    \n",
    "    \n",
    "user_with_checkins = set()\n",
    "for checkin in checkins:\n",
    "    user_with_checkins.add(checkin[0])\n",
    "    \n",
    "print(\"Total number of users with checkins: \", len(user_with_checkins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into test and train \n",
    "# test sample size is 7092\n",
    "test = set()\n",
    "train = set()\n",
    "for checkin in checkins:\n",
    "    user = checkin[0]\n",
    "    if len(test) <= 7092:\n",
    "        test.add(user)\n",
    "    elif user not in test:\n",
    "        train.add(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 locations:  [55033, 58725, 19542, 66171, 10259, 9410, 14470, 22831, 10190, 23256]\n"
     ]
    }
   ],
   "source": [
    "locations = dict()\n",
    "for (user, location) in checkins:\n",
    "    if user in train:\n",
    "        if location in locations.keys():\n",
    "            locations[location] += 1\n",
    "        else:\n",
    "            locations[location] = 1\n",
    "            \n",
    "            \n",
    "# sort by checkins and get top-10 locations\n",
    "sorted_locations = sorted(locations.items(), key = lambda loc: loc[1], reverse=True)\n",
    "\n",
    "locations = [[key, value] for key, value in sorted_locations]\n",
    "\n",
    "\n",
    "top_10 = []\n",
    "for location in locations[:TOP_NUMBER]:\n",
    "    top_10.append(location[0])\n",
    "    \n",
    "print(\"Top-10 locations: \", top_10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15388411109544622"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metric\n",
    "hits = 0\n",
    "for (user, location) in checkins: \n",
    "    if user in test:\n",
    "        if location in top_10:  # how many test users checked in in certain loction\n",
    "            hits += 1\n",
    "            \n",
    "metric_1 = (hits / TOP_NUMBER) / len(test)\n",
    "metric_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_locations = dict()\n",
    "\n",
    "for (user, location) in checkins:\n",
    "    if user in train:\n",
    "        leader = clusters_leaders[user]\n",
    "        if leader in cluster_locations.keys():\n",
    "            if location in cluster_locations[leader].keys():\n",
    "                cluster_locations[leader][location] += 1     # number of checkins for each location each cluster (leader)\n",
    "            else:\n",
    "                cluster_locations[leader][location] = 1\n",
    "        else:\n",
    "            cluster_locations[leader] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33793, 188705, 27488, 31259, 608698, 398421, 19542, 280538, 74677, 9410]\n"
     ]
    }
   ],
   "source": [
    "# sort locations in descending \n",
    "for leader in cluster_locations:\n",
    "    sorted_cluster_locations = sorted(cluster_locations[leader].items(), key = lambda loc: loc[1], reverse=True)\n",
    "    cluster_locations[leader] = [[key, value] for key, value in sorted_cluster_locations]\n",
    "    \n",
    "        \n",
    "top_10_per_cluster = dict() \n",
    "\n",
    "    \n",
    "for leader in cluster_locations:\n",
    "    for location in cluster_locations[leader][:TOP_NUMBER]:\n",
    "        if leader not in top_10_per_cluster:\n",
    "            top_10_per_cluster[leader] = []\n",
    "        top_10_per_cluster[leader].append(location[0])\n",
    "    \n",
    "print(top_10_per_cluster[0])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2764415621034823"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metric for clusters\n",
    "hits = 0\n",
    "for (user, location) in checkins:\n",
    "    if user in test:\n",
    "        leader = clusters_leaders[user]\n",
    "        if leader in top_10_per_cluster and location in top_10_per_cluster[leader]:\n",
    "            hits += 1\n",
    "            \n",
    "metric_2 = (hits / TOP_NUMBER) / len(test)\n",
    "metric_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.15388411109544622\n",
      "Precision for clusters:  0.2764415621034823\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", metric_1)\n",
    "print(\"Precision for clusters: \", metric_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
